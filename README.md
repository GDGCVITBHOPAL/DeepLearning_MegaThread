# ğŸ§  DeepLearning_MegaThread

Welcome to the official code and experiment hub for the **DeepLearning MegaThread** â€” a 5-part blog series by the **GDGC ML Team** that dives into the practical side of deep learning with a perfect blend of **theory, code, and good vibes**. ğŸš€

Weâ€™re talking **hands-on implementation**, **clear explanations**, and **models that actually work** â€” all wrapped into weekly drops designed to make deep learning more accessible, exciting, and deployable.

---

## âœ¨ Blog Highlights

### ğŸ”¢ 1. **Transfer Learning Fundamentals**  
**Author:** *Anaant Raj*  
Anaant kicked things off with a banger ğŸ’¥ by walking us through how to **fine-tune MobileNetV2 on CIFAR-10**.  
From loading pre-trained weights to understanding which layers to freeze, this post is a must-read if youâ€™re diving into **transfer learning**.

ğŸ”— [Read the blog](https://medium.com/dsc-vit-bhopal/introducing-transfer-learning-fundamentals-cifar-10-mobilenetv2-fine-tuning-and-beyond-d747f73f216c)  

---

### ğŸ§  2. **Understanding GPT-2 & the Rise of Transformers**  
**Author:** *Nidhi Rohra*  
Nidhi broke down the **GPT-2 architecture** and the entire Transformer revolution with crystal-clear visuals and that golden example:  
> â€œIn â€˜The cat sat on the mat,â€™ the word â€˜satâ€™ pays attention to both â€˜catâ€™ and â€˜mat.â€™â€ ğŸ¤¯

She also included runnable code and a clean walkthrough of why decoder-only models like GPT-2 are so powerful.

ğŸ”— [Read the blog](https://medium.com/dsc-vit-bhopal/understanding-gpt-2-the-evolution-of-transformers-in-ai-464d94164baa) 

---

### ğŸ” 3. **VisionGPT: Tiny Transformer, Mighty Vision!**  
**Author:** *Arihant Bhandari*  
CNNs are great at extracting local features. Transformers are amazing at global reasoning. So... why not both?  
**MobileViT** does just that â€” blending MobileNetâ€™s efficiency with ViTâ€™s attention mechanism for a hybrid model that punches way above its size.

We experiment with **MobileViT-XXS** under multiple settings using Tiny ImageNet to test how image resolution, pretraining, and architecture affect performance.

ğŸ”— [Read the blog](https://medium.com/dsc-vit-bhopal/visiongpt-mobilevit-tiny-transformer-mighty-vision-b9a7f908d490)

---

### ğŸ›¡ï¸ 4. **From Vulnerable to Vigilant: Adversarial Training for LLMs**  
**Author:** *Samyak Waghdare*  
This oneâ€™s all about **securing GPT-like models** against manipulation. Samyak walks you through how adversarial prompts work, how to generate them using libraries like `TextAttack`, and how adversarial training can improve model robustness â€” without sacrificing performance.

ğŸ”— [Read the blog](https://medium.com/dsc-vit-bhopal/from-vulnerable-to-vigilant-how-adversarial-training-strengthens-gpt-and-other-large-language-a1c99b68c744)

---

### ğŸ¤– 5. **Gemini-Senpai, Notice Our Humanity: Prompting LLMs to Sound Human**  
**Author:** *Sahil Garje*  
In this hilarious and thought-provoking finale, Sahil takes on the challenge of **humanizing GPT output** â€” testing dozens of prompting techniques and measuring them using GPTZero, a state-of-the-art AI detector. It's prompt engineering meets performance art.

ğŸ”— [Read the blog](https://medium.com/dsc-vit-bhopal/gemini-senpai-notice-our-humanity-80d772589125)

---

## ğŸ“ What's in This Repo?

All the code, experiments, and notebooks from the series â€” neatly organized for you to run, tweak, and learn from.

### ğŸ“Œ VisionGPT Experiments

ğŸ“‚ Folder: `VisionGPT/`

| Notebook | Description |
|----------|-------------|
| `mobilevit_xxs_scratch_64.ipynb` | Trains MobileViT-XXS from scratch on 64Ã—64 Tiny ImageNet images. |
| `mobilevit_xxs_pretrained_64.ipynb` | Fine-tunes pretrained MobileViT-XXS on 64Ã—64 Tiny ImageNet. |
| `mobilevit_xxs_scratch_96.ipynb` | Trains MobileViT-XXS from scratch on 96Ã—96 resolution input. |
| `mobilevit_xxs_pretrained_96.ipynb` | Fine-tunes pretrained MobileViT-XXS on 96Ã—96 Tiny ImageNet. |

### ğŸ“Œ Adversarial Training for GPT Experiments

ğŸ“‚ Folder: `GPTAdversarial/`

| Notebook | Description |
|----------|-------------|
| `gdgc-llm-adversarial.ipynb` | Core training + evaluation pipeline for adversarial robustness. |
| `gdgc-llm-adversarial-training-fgsm.ipynb` | Implements FGSM adversarial training on LLMs. |
| `gdgc-llm-adversarial-training-text-attack-deepbugword.ipynb` | Uses `TextAttack` with the DeepBugWord attack method. |
| `gdgc-llm-adversarial-training-text-attack-textfooler.ipynb` | Uses `TextAttack` with the TextFooler method. |

---

## ğŸ’¬ Why This Series?

Because letâ€™s face it â€” deep learning can feel like a black box sometimes.  
This series is our way of turning that box transparent.

- ğŸ¤– From pre-trained models to attention mechanisms  
- ğŸ§  From â€œhow it worksâ€ to â€œwhy it mattersâ€  
- ğŸ’» From paper to practice

Whether you're a beginner or a practitioner brushing up on fundamentals, weâ€™ve got something here for you.

---

## ğŸ™Œ Meet the Team

ğŸ§  **Arihant Bhandari**  
ğŸ§  **Sahil Garje**  
ğŸ§  **Anaant Raj**  
ğŸ§  **Nidhi Rohra**  
ğŸ§  **Samyak Waghdare**

We're the GDGC ML Team â€” on a mission to make deep learning more practical, fun, and open to all.

---

## ğŸ“¬ Contribute / Connect

Spotted a bug, want to contribute, or just want to say hi?  
Open an issue, fork the repo, or comment on the blog posts â€” we love hearing from fellow learners and builders.

ğŸ§  Happy Learning from the GDGC ML Team!

ğŸ‰ This wraps up our 5-part DeepLearning MegaThread series â€” thanks for following along!  
We hope it sparked ideas, curiosity, and a love for building. Until next time! ğŸ’™
